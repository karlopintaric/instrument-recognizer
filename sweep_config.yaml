# Configuration for the trainer
---
# Sweep config
method: bayes
metric:
  name: mAP
  goal: maximize

# Dataloader settings
parameters:
  train_dir:
    value:
      ./data/processed/all_sync/IRMAS_Training_Data

  valid_dir: 
    value:
      ./data/raw/IRMAS_Validation_Data

  # Preprocessing done on raw audio
  preprocess:
    parameters:
      PreprocessPipeline:
        parameters:
          target_sr: 
            value:
              16000

  # Transforms applied on raw audio after preprocessing
  transforms:
    parameters:
      FeatureExtractor:
        parameters:
          sr:
            value:
              16000

  # Augmentations for spectrograms
  signal_augments:
    parameters:
      RepeatAudio:
        parameters:
          max_repeats:
            distribution: int_uniform
            min: 2
            max: 5

  spec_augments:
    parameters:
      MaskFrequency:
        parameters:
          max_mask_length:
            distribution: int_uniform
            min: 0
            max: 30
      
      MaskTime:
        parameters:
          max_mask_length:
            distribution: int_uniform
            min: 0
            max: 200

  batch_size: 
    value:
      8

  # Training settings

  
  loss:
    parameters:
      FocalLoss:
        parameters:
          alpha:
            values: [-1, 0.25, 0.5, 0.75]
          gamma:
            values: [1,2,3]

  
  optimizer:
    parameters:
      AdamW:
        parameters:
          lr:
            distribution: log_uniform_values
            min: 1.0E-5
            max: 1.0E-2
          weight_decay:
            value: 0
  
  LLRD:
    parameters:
      base_lr:
        distribution: log_uniform_values
        min: 1.0E-7
        max: 1.0E-3

      lr_decay_rate:
        distribution: uniform
        min: 0.5
        max: 0.99

      weight_decay:
        distribution: log_uniform_values
        min: 1.0E-8
        max: 1.0E-2

  # Gradient accumulation
  num_accum: 
    values: [2, 4, 6, 8]

  EPOCHS: 
    distribution: int_uniform
    min: 2
    max: 10
    
  scheduler:
    parameters:
      CosineAnnealingLR:
        parameters:
          eta_min:
            value: 0

  save_best_model: 
    value:
      True
  
  verbose: 
    value:
      True
  
  metrics:
    value:
    - hamming_score 
    - zero_one_score
    - mAP
    - mean_f1_score

early_terminate:
  type: hyperband
  eta: 2
  min_iter: 3








